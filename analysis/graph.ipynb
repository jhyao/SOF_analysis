{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:18:11,350 data.config.config DEBUG: db setting: {'host': 'localhost', 'port': 3306, 'user': 'root', 'passwd': 'LOVEyjh201697', 'database': 'sof_basic', 'max_connections': 10, 'charset': 'utf8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:18:11,355 data.config.config DEBUG: redis setting: {'host': 'localhost', 'port': 6379, 'password': None, 'db': 0, 'maxsize': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:18:11,374 data.config.config DEBUG: db setting: {'host': 'localhost', 'port': 3306, 'user': 'root', 'passwd': 'LOVEyjh201697', 'database': 'sof_analysis', 'max_connections': 10, 'charset': 'utf8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:18:11,378 data.config.config DEBUG: redis setting: {'host': 'localhost', 'port': 6379, 'password': None, 'db': 0, 'maxsize': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:18:12,050 matplotlib.backends DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "step1: filtrate related weight \n",
    "step2: make weighted graph\n",
    "step3: adjust weight with adjust_weight_file\n",
    "step4: get small components, put them all in 'others' class\n",
    "step5: check ignore_tags_file\n",
    "step6: get laplacian matrix, get eigvecs\n",
    "step7-pre1: pagerank on graph\n",
    "step7-pre2: get top 100 tag\n",
    "step7-pre3: get component graph of these 100 tag\n",
    "step7: clustering with k-means, move small group to 'others' class\n",
    "step8: match group name, draw graph, save file\n",
    "step9: check clustering result, with classify method\n",
    "\"\"\"\n",
    "\n",
    "import functools\n",
    "from scipy.sparse.linalg import eigs\n",
    "import numpy as np\n",
    "\n",
    "from analysis.classify_tag_v1 import TagClassifier\n",
    "from analysis.common import *\n",
    "import logging\n",
    "\n",
    "from data.cdn.sof_cdn import TagsCDN, TagRelatedCDN, CoreTagClfCache, CoreTagRankCache\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def related_weight_filter(related_weight, min_weight=0.1, save=True, msg=None):\n",
    "    # delete related with small weight\n",
    "    related_weight_filted = list(filter(lambda related: related[2] > min_weight, related_weight))\n",
    "    save_step_data(related_weight_filted, step='related_weight_filted', transfer_item=lambda item: f'{item[0]} {item[1]} {item[2]}',\n",
    "                   save=save, msg=msg)\n",
    "    logger.info(f'related weight filter finished, related: {len(related_weight_filted)}')\n",
    "    return related_weight_filted\n",
    "\n",
    "def make_graph(related_weight_filted, save=True, msg=None):\n",
    "    graph = nx.Graph()\n",
    "    for related in related_weight_filted:\n",
    "        graph.add_edge(related[0], related[1], weight=float(related[2]))\n",
    "    save_graph(graph, 'tag-link.png', save=save, msg=msg)\n",
    "    logger.info(f'create graph finish, tags: {len(graph.nodes)}')\n",
    "    return graph\n",
    "\n",
    "\n",
    "def weight_adjust(graph, adjust_file_path, save=True, msg=None):\n",
    "    if adjust_file_path:\n",
    "        adjust_weight = load_file(adjust_file_path)\n",
    "        for related in adjust_weight:\n",
    "            if graph.has_edge(related[0], related[1]):\n",
    "                graph[related[0]][related[1]]['weight'] = related[2]\n",
    "                logger.debug(f\"adjust weight: {related[0]} {related[1]} {graph[related[0]][related[1]]['weight']}\")\n",
    "            else:\n",
    "                graph.add_edge(related[0], related[1], weight=related[2])\n",
    "                logger.debug(f\"add weight: {related[0]} {related[1]} {related[2]}\")\n",
    "        save_graph(graph, 'tag-adjusted.png', save=save, msg=msg)\n",
    "        save_step_data(adjust_weight, 'adjust_weight.txt', save=save, msg=msg)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def get_center_tags(graph, k):\n",
    "    tagranks = nx.pagerank(graph)\n",
    "    tags = [(tag, tagranks[tag]) for tag in tagranks]\n",
    "    tags.sort(key=lambda item: item[1], reverse=True)\n",
    "    center_tags = [item[0] for item in tags[:k]]\n",
    "    logger.info(f'center tags : {center_tags}')\n",
    "    return center_tags\n",
    "\n",
    "\n",
    "def center_tags_group(graph: nx.Graph, center_tags: list):\n",
    "    subgraph = graph.subgraph(center_tags)\n",
    "    components = nx.connected_components(subgraph)\n",
    "    result = []\n",
    "    for component in components:\n",
    "        i = min([center_tags.index(tag) for tag in component])\n",
    "        result.append(center_tags[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "def laplacian_eigs(G, k, nodelist=None, save=True, msg=None):\n",
    "    L = nx.laplacian_matrix(G, nodelist=nodelist)\n",
    "    node_num = len(nodelist) if nodelist else len(G.nodes)\n",
    "    eigval, eigvec = eigs(L, node_num - 2)\n",
    "    dim = len(eigval)\n",
    "    dictEigval = dict(zip(eigval, range(0, dim)))\n",
    "    eigval_sort = np.sort(eigval)\n",
    "    logger.debug(eigval_sort)\n",
    "    kEig = eigval_sort[0: k]\n",
    "    ix = [dictEigval[val] for val in kEig]\n",
    "    eigvecs = eigvec[:, ix]\n",
    "    if save:\n",
    "        file_path = create_step_file_path('eigvecs.txt')\n",
    "        np.savetxt(file_path, eigvecs)\n",
    "    logger.info('gen eigvecs finished')\n",
    "    return eigvecs\n",
    "\n",
    "\n",
    "def graph_clustering(graph, k=8, individual_tags=None, ignore_tags=None, min_component=3, save=True, msg=None):\n",
    "    # move small components to 'others' class, then do clustering on large components\n",
    "    k = len(individual_tags) if individual_tags else k\n",
    "    components = nx.connected_components(graph)\n",
    "    small_node_sets = set()\n",
    "    nodelist = set()\n",
    "    for c in components:\n",
    "        if len(c) < min_component:\n",
    "            small_node_sets |= c\n",
    "            logger.debug('small component ' + str(c))\n",
    "        else:\n",
    "            nodelist |= c\n",
    "    # move ignore tags to others\n",
    "    if ignore_tags:\n",
    "        small_node_sets |= ignore_tags\n",
    "        nodelist -= ignore_tags\n",
    "        save_step_data(ignore_tags, 'ignore_tags.txt', save=save, msg=msg)\n",
    "    nodelist = list(nodelist)\n",
    "    # get laplacian matrix and do clustering\n",
    "    eigvecs = laplacian_eigs(graph, k, nodelist=nodelist)\n",
    "    # get init center for kmeans\n",
    "    if individual_tags:\n",
    "        init_center = eigvecs[[nodelist.index(center) for center in individual_tags if center not in small_node_sets]]\n",
    "        clf = KMeans(k, init=init_center).fit(eigvecs).labels_\n",
    "    else:\n",
    "        clf = KMeans(k).fit(eigvecs).labels_\n",
    "\n",
    "    # match k-means labels with nodelist order\n",
    "    result = {}\n",
    "    for i, c in enumerate(clf):\n",
    "        if c in result:\n",
    "            result[c].append(nodelist[i])\n",
    "        else:\n",
    "            result[c] = [nodelist[i]]\n",
    "\n",
    "    # mark every class with the most important tag of the class\n",
    "    tagranks = nx.pagerank(graph)\n",
    "    for c in list(result.keys()):\n",
    "        if len(result[c]) < min_component:\n",
    "            # move small class to others\n",
    "            small_node_sets |= set(result.pop(c))\n",
    "            continue\n",
    "        result[c].sort(key=functools.cmp_to_key(lambda a, b: tagranks[a] - tagranks[b]), reverse=True)\n",
    "        result[result[c][0]] = result[c]\n",
    "        result.pop(c)\n",
    "    # add small components to final clf result\n",
    "    result['others'] = list(small_node_sets)\n",
    "    save_graph(graph, 'tag-clf.png', clf=result, save=save, msg=msg)\n",
    "    save_step_data(result, 'tag-clf.json', save=save, msg=msg)\n",
    "    save_step_data(tagranks, 'tag-rank.json', save=save, msg=msg)\n",
    "    return result, tagranks\n",
    "\n",
    "\n",
    "def save_to_cdn(tag_clf, tag_rank):\n",
    "    CoreTagClfCache.set(tag_clf)\n",
    "    CoreTagRankCache.set(tag_rank)\n",
    "\n",
    "\n",
    "min_weight = 0.3\n",
    "min_component = 5\n",
    "clustering_method = ClusterMethod.kmeans\n",
    "output_path = r'E:\\SOF\\file\\tag_clustering_v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:56:51,106 __main__ INFO: create graph finish, tags: 1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-09 14:56:51,628 __main__ INFO: center tags : ['android', 'java', 'c#', 'javascript', 'python', 'ios', 'c++', 'php', 'css', 'jquery', 'sql', 'ruby-on-rails', 'r', 'html', 'c', 'angular', 'asp.net', 'sql-server', 'git', 'objective-c', 'swift', 'iphone', 'node.js', 'algorithm', 'django', 'angularjs', 'mysql', 'swing', 'amazon-web-services', 'asp.net-mvc', 'azure', '.net', 'wpf', 'spring', 'xml', 'apache-spark', 'ruby', 'laravel', 'linux', 'hadoop', 'xcode', 'excel', 'bash', 'firebase', 'unit-testing', 'machine-learning', 'entity-framework', 'oracle', 'qt', 'facebook']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c#', 'java', 'linux', 'mysql', 'javascript', 'sql', 'ios', 'facebook', 'apache-spark', 'git', 'xml', 'ruby-on-rails', 'azure', 'php', 'python', 'excel', 'bash', 'c++', 'amazon-web-services', 'algorithm', 'angular', 'android', 'unit-testing', 'hadoop', 'r', 'c']\n"
     ]
    }
   ],
   "source": [
    "related_weight = TagRelatedCDN.get_tag_related_filtered(0.3)\n",
    "graph = make_graph(related_weight, save=False)\n",
    "center_tag = get_center_tags(graph, 50)\n",
    "cores = center_tags_group(graph, center_tag)\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist = []\n",
    "for component in nx.connected_components(graph):\n",
    "    if len(component) >= 10:\n",
    "        nodelist.extend(component)\n",
    "L = nx.laplacian_matrix(graph, nodelist=nodelist)\n",
    "eigval, eigvec = eigs(L, len(nodelist) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n[(-3.1825266467135454e-15+0j), (0.0051477361342167635+0j), (0.0066049747327374805+0j), (0.006817871030448737+0j), (0.010118338890117798+0j), (0.012688235165480443+0j), (0.014416873666944937+0j), (0.018556120425836285+0j), (0.02004568982394964+0j), (0.02265716142254052+0j), (0.024556714694509298+0j), (0.033322977189318106+0j), (0.034632156374678716+0j), (0.03588821570194735+0j), (0.044936076346399886+0j), (0.04717312433130673+0j), (0.047867668034975996+0j), (0.0681514622906278+0j), (0.06987999582298814+0j), (0.07597293139839012+0j), (0.07959181403439013+0j), (0.08139612170329752+0j), (0.09227315167488148+0j), (0.09575882682834454+0j), (0.10129616781899947+0j), (0.10266596117257776+0j), (0.11828053505906513+0j), (0.12052993595224656+0j), (0.1220191010299754+0j), (0.12736977837080585+0j), (0.13314729810598985+0j), (0.13812862455891806+0j), (0.13937720189669356+0j), (0.1408567485735605+0j), (0.14455478498506694+0j), (0.14789177399882847+0j), (0.1545455484667187+0j), (0.15879122856715389+0j), (0.1606123575191422+0j), (0.17013115470833443+0j), (0.17179769083739221+0j), (0.19142896871258708+0j), (0.19841335361984283+0j), (0.19871125894037608+0j), (0.20331826372330164+0j), (0.2067160265794577+0j), (0.20952855848535765+0j), (0.21910781520794104+0j), (0.22822435748996628+0j), (0.23130764892514166+0j)]\n"
     ]
    }
   ],
   "source": [
    "eigval_sorted = sorted(eigval)\n",
    "temp = [abs(eigval_sorted[i] - eigval_sorted[i+1]) for i in range(0,1000)]\n",
    "k = temp.index(max(temp))\n",
    "print(k)\n",
    "print(eigval_sorted[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}